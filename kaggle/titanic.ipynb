{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Prepare the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T00:42:32.503060",
     "start_time": "2017-02-12T00:42:32.019950"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "init_cell": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T00:42:34.134299",
     "start_time": "2017-02-12T00:42:32.505034"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "init_cell": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T00:42:34.140995",
     "start_time": "2017-02-12T00:42:34.136015"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def save_result(filename, predictions):\n",
    "    with open('output/titanic_{}.csv'.format(filename), 'w') as fd:\n",
    "        print('PassengerId,Survived', file=fd)\n",
    "        for passenger, survived in predictions:\n",
    "            print(\"{},{}\".format(passenger, int(survived)), file=fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-11T19:59:37.262952",
     "start_time": "2017-02-11T19:59:37.257923"
    },
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The data should be downloaded from the following links and placed in the `./datasets` folder with the given name:\n",
    "\n",
    "- [titanic_train.csv](https://www.kaggle.com/c/titanic/download/train.csv)\n",
    "- [titanic_test.csv](https://www.kaggle.com/c/titanic/download/test.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Read the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T01:16:30.120288",
     "start_time": "2017-02-12T01:16:30.080574"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "init_cell": false
   },
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('./datasets/titanic_train.csv')\n",
    "test_csv = pd.read_csv('./datasets/titanic_test.csv')\n",
    "all_csv = pd.concat([train_csv, test_csv])\n",
    "data = all_csv.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Function to split train set into a train and validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T00:56:32.389416",
     "start_time": "2017-02-12T00:56:32.363329"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def split_train_validation_test(data, valid_ration=0.2):\n",
    "    # Split train/test\n",
    "    train = data.iloc[[not pd.isnull(v) for v in data['Survived']]].copy()\n",
    "    test = data.iloc[[pd.isnull(v) for v in data['Survived']]].copy()\n",
    "    # Split train/validation\n",
    "    valid_ids = np.random.randint(0, len(train), int(len(train) * valid_ration))\n",
    "    train = data.iloc[[i for i in range(len(train)) if i not in valid_ids]].copy()\n",
    "    valid = data.iloc[valid_ids].copy()\n",
    "    # Split data/labels\n",
    "    train_data = train.ix[:, train.columns != 'Survived'].copy()\n",
    "    train_labels = train[['Survived']].as_matrix().ravel()\n",
    "    valid_data = valid.ix[:, train.columns != 'Survived'].copy()\n",
    "    valid_labels = valid[['Survived']].as_matrix().ravel()\n",
    "    # Remove label from test data\n",
    "    test_data = test.drop('Survived', 1)\n",
    "    return train_data, train_labels, valid_data, valid_labels, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T00:56:32.819064",
     "start_time": "2017-02-12T00:56:32.771372"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>330877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>54.0</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>349909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>347742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>237736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Cabin Embarked     Fare  \\\n",
       "0  22.0   NaN        S   7.2500   \n",
       "1  38.0   C85        C  71.2833   \n",
       "2  26.0   NaN        S   7.9250   \n",
       "3  35.0  C123        S  53.1000   \n",
       "4  35.0   NaN        S   8.0500   \n",
       "5   NaN   NaN        Q   8.4583   \n",
       "6  54.0   E46        S  51.8625   \n",
       "7   2.0   NaN        S  21.0750   \n",
       "8  27.0   NaN        S  11.1333   \n",
       "9  14.0   NaN        C  30.0708   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris      0            1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...      0            2   \n",
       "2                             Heikkinen, Miss. Laina      0            3   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)      0            4   \n",
       "4                           Allen, Mr. William Henry      0            5   \n",
       "5                                   Moran, Mr. James      0            6   \n",
       "6                            McCarthy, Mr. Timothy J      0            7   \n",
       "7                     Palsson, Master. Gosta Leonard      1            8   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)      2            9   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)      0           10   \n",
       "\n",
       "   Pclass     Sex  SibSp  Survived            Ticket  \n",
       "0       3    male      1       0.0         A/5 21171  \n",
       "1       1  female      1       1.0          PC 17599  \n",
       "2       3  female      0       1.0  STON/O2. 3101282  \n",
       "3       1  female      1       1.0            113803  \n",
       "4       3    male      0       0.0            373450  \n",
       "5       3    male      0       0.0            330877  \n",
       "6       1    male      0       0.0             17463  \n",
       "7       3    male      3       0.0            349909  \n",
       "8       3  female      0       1.0            347742  \n",
       "9       2  female      1       1.0            237736  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-11T20:32:12.526464",
     "start_time": "2017-02-11T20:32:12.523579"
    },
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-11T22:05:59.365255",
     "start_time": "2017-02-11T22:05:59.360602"
    },
    "deletable": true,
    "editable": true
   },
   "source": [
    "Extract manually features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T01:16:33.195650",
     "start_time": "2017-02-12T01:16:33.177551"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "data['LastName'] = [v.split(',')[0] for v in data['Name']]\n",
    "data['CabinLetter'] = [re.sub(r'\\d', '', v) if not pd.isnull(v) else np.nan for v in data['Cabin']]\n",
    "data['CabinNumber'] = [int('0'+re.sub(r'\\D', '', v)) if not pd.isnull(v) else np.nan for v in data['Cabin']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Remove specific columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T01:16:33.522450",
     "start_time": "2017-02-12T01:16:33.514614"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "columns_to_remove = ['PassengerId', 'Name']\n",
    "for column in columns_to_remove:\n",
    "    if column in data:\n",
    "        data.drop(column, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T01:16:33.741279",
     "start_time": "2017-02-12T01:16:33.694370"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "columns_to_encode = ['Sex', 'Embarked', 'Ticket', 'Cabin', 'CabinLetter', 'LastName']\n",
    "\n",
    "for column in columns_to_encode:\n",
    "    # Prepare a label encoder\n",
    "    le = LabelEncoder()\n",
    "    # Replace NaN by string equivalent\n",
    "    data[column].fillna('NAN', inplace=True)\n",
    "    # Fit the label encoder\n",
    "    le.fit([v for v in data[column] if v])\n",
    "    # Replace the column\n",
    "    data[column] = le.transform(data[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T01:16:33.919815",
     "start_time": "2017-02-12T01:16:33.849088"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "columns_to_onehot = ['Sex', 'Ticket', 'LastName', 'CabinLetter', 'CabinNumber', 'Embarked']\n",
    "\n",
    "for column in columns_to_onehot:\n",
    "    onehot = pd.get_dummies(data[column], column)\n",
    "    data = pd.concat([data, onehot], axis=1, join_axes=[data.index])\n",
    "    data.drop(column, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T01:16:35.837418",
     "start_time": "2017-02-12T01:16:35.531270"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1309 entries, 0 to 417\n",
      "Columns: 1955 entries, Age to Embarked_3\n",
      "dtypes: float64(4), int64(9), uint8(1942)\n",
      "memory usage: 2.6 MB\n"
     ]
    }
   ],
   "source": [
    "data[:10]\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T01:16:38.694547",
     "start_time": "2017-02-12T01:16:38.656842"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_data, train_labels, valid_data, valid_labels, test_data = split_train_validation_test(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T01:16:40.764748",
     "start_time": "2017-02-12T01:16:40.697529"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imputer = Imputer()\n",
    "imputer.fit(train_data)\n",
    "imputer.fit(valid_data)\n",
    "X = imputer.transform(train_data)\n",
    "V = imputer.transform(valid_data)\n",
    "T = imputer.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-11T23:17:26.197667",
     "start_time": "2017-02-11T23:17:26.194719"
    },
    "deletable": true,
    "editable": true,
    "heading_collapsed": true
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "source": [
    "Build and train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T01:16:43.208802",
     "start_time": "2017-02-12T01:16:43.116659"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-11T23:19:08.204637",
     "start_time": "2017-02-11T23:19:08.199353"
    },
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "source": [
    "Evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T01:16:43.220450",
     "start_time": "2017-02-12T01:16:43.210414"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8202247191011236"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred = rf.predict(V)\n",
    "accuracy_score(valid_labels, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "source": [
    "Train with validation, predict test set and save results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T01:16:43.258684",
     "start_time": "2017-02-12T01:16:43.222462"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rf.fit(V, valid_labels)\n",
    "pred = rf.predict(T)\n",
    "save_result('random_forest', zip(test_csv['PassengerId'], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "heading_collapsed": true
   },
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T01:16:43.793233",
     "start_time": "2017-02-12T01:16:43.260787"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8370786516853933"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X, train_labels)\n",
    "pred = ada.predict(V)\n",
    "accuracy_score(valid_labels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T01:16:43.995777",
     "start_time": "2017-02-12T01:16:43.794801"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ada.fit(V, valid_labels)\n",
    "pred = ada.predict(T)\n",
    "save_result('adaboost', zip(test_csv['PassengerId'], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-11T23:19:54.805272",
     "start_time": "2017-02-11T23:19:54.802707"
    },
    "deletable": true,
    "editable": true,
    "heading_collapsed": true
   },
   "source": [
    "###Â Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T01:16:44.004499",
     "start_time": "2017-02-12T01:16:43.998853"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_ = pd.get_dummies(train_labels).as_matrix()\n",
    "yv_ = pd.get_dummies(valid_labels).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T01:16:44.381637",
     "start_time": "2017-02-12T01:16:44.006919"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(1953,)))\n",
    "model.add(Dense(1024))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T01:16:44.391217",
     "start_time": "2017-02-12T01:16:44.383068"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "batchnormalization_13 (BatchNorm (None, 1953)          7812        batchnormalization_input_5[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "dense_13 (Dense)                 (None, 1024)          2000896     batchnormalization_13[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_14 (BatchNorm (None, 1024)          4096        dense_13[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 256)           262400      batchnormalization_14[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_15 (BatchNorm (None, 256)           1024        dense_14[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_15 (Dense)                 (None, 2)             514         batchnormalization_15[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 2)             0           dense_15[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 2,276,742\n",
      "Trainable params: 2,270,276\n",
      "Non-trainable params: 6,466\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T01:16:44.448082",
     "start_time": "2017-02-12T01:16:44.393855"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T01:16:44.468518",
     "start_time": "2017-02-12T01:16:44.449909"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: expected batchnormalization_input_5 to have shape (None, 1953) but got array with shape (731, 1954)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-4604c568320f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/gpu:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myv_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/fabien/.conda/envs/deep_learning/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/fabien/.conda/envs/deep_learning/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1114\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1117\u001b[0m         \u001b[0;31m# prepare validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fabien/.conda/envs/deep_learning/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1027\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m                                    \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m                                    exception_prefix='model input')\n\u001b[0m\u001b[1;32m   1030\u001b[0m         y = standardize_input_data(y, self.output_names,\n\u001b[1;32m   1031\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fabien/.conda/envs/deep_learning/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: expected batchnormalization_input_5 to have shape (None, 1953) but got array with shape (731, 1954)"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model.fit(X, y_, validation_data=(V, yv_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T01:16:44.468974",
     "start_time": "2017-02-12T00:16:43.345Z"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    pred = model.predict_classes(V)\n",
    "    \n",
    "print(accuracy_score(pred, valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T01:16:44.469296",
     "start_time": "2017-02-12T00:16:43.351Z"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model.fit(V, yv_)\n",
    "    pred = model.predict_classes(T)\n",
    "    \n",
    "save_result('ann', zip(test_csv['PassengerId'], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T00:32:51.856433",
     "start_time": "2017-02-12T00:32:51.850856"
    },
    "deletable": true,
    "editable": true,
    "heading_collapsed": true
   },
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T01:29:18.990931",
     "start_time": "2017-02-12T01:29:15.513026"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8166894664842681\n",
      "Best parameters: {'splitter': 'best', 'criterion': 'gini', 'max_features': None}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "\n",
    "parameter_grid = {\n",
    "                 'criterion': ['gini','entropy'],\n",
    "                 'splitter': ['best','random'],\n",
    "                 'max_features': [None, 'auto', 'sqrt', 'log2'],\n",
    "                 }\n",
    "\n",
    "cross_validation = StratifiedKFold(train_labels, n_folds=5)\n",
    "\n",
    "grid_search = GridSearchCV(dtc,\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=cross_validation)\n",
    "\n",
    "grid_search.fit(X, train_labels)\n",
    "\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T01:18:36.040331",
     "start_time": "2017-02-12T01:18:35.970117"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8539325842696629"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, train_labels) \n",
    "pred = model.predict(V)\n",
    "accuracy_score(valid_labels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-12T01:18:36.056295",
     "start_time": "2017-02-12T01:18:36.042967"
    },
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(V, valid_labels)\n",
    "pred = ada.predict(T)\n",
    "save_result('last', zip(test_csv['PassengerId'], pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "141px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
